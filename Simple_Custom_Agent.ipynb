{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SGirXAFQl-y1ywYxq072HOHF5yOBPNS-",
      "authorship_tag": "ABX9TyO/JosCzZT/8Ugiw1IIH5Z1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuccaRomagnolli/Aritficial-Inteligence/blob/main/Simple_Custom_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building your custom agent\n",
        "\n",
        "In this project i made a LLM using deep-seek api that racting with the personality traits wich you indicate. it stuff is useffull to apply in websites, landing pages and for businessperson"
      ],
      "metadata": {
        "id": "V5LXcgRU4fwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the packages\n",
        "!pip install dotenv -q\n",
        "!pip install openai -q\n",
        "!pip install pypdf -q\n",
        "!pip install gradio -q"
      ],
      "metadata": {
        "id": "PIa553Y0pA6q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the librarys\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from pypdf import PdfReader\n",
        "import gradio as gr\n",
        "import os"
      ],
      "metadata": {
        "id": "y8cXgYTFoO2I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt about you\n",
        "name = \"Lucca\"\n",
        "\n",
        "data = [\"\"\"\n",
        "Meu nome completo é Lucca Maximus Romagnolli, eu tenho 21 anos, nasci em 24 de novembro de 2003 no Rio de Janeiro - Brasil e atualmente moro em Brasília.\n",
        "Atualmente estou no quarto semestre de Egenharia Civil na Universidade Federal de Brasilia.\n",
        "As áreas profissionais que tenho mais enteresse são: mercado financeiro, engenharia e tecnologia em geral\n",
        "Minha comida preferida e file de frango á parmegiana e meu doce preferido é sorvete de pistache.\n",
        "Pretendo fazer uma pós-graduação no exterior após me formar: Suíça ou Estados Unidos.\n",
        "Meus principais hobbies são: Leitura, programação e viagens\n",
        "Vim para Brasília aos 2 anos de idade e resido aqui desde então.\n",
        "Torço para o time de futebol brasileiro flamengo.\n",
        "Tenho um grande sonho de fundar minha própria empresa e gerar valor para sociedade através dos meus serviços.\n",
        "Tenho 1.93 m de altura, olhos verdes, pele branca, calço 44, canhoto, cabelos castanhos e médios.\n",
        "Sou cristão, Liberal Êconomico (defensor de um estado pequeno e auxiliador das minorias), heterossexual, apesar do meu conservadorismo sou mente aberta para qualquer discussão e ponto de vista.\n",
        "Meu primeiro emprego foi na Caesb como estagiário de Engenharia Civil, aprendi bastante sobre hidráulica, projetos, elétrica e saneamento devido a multidiciplinaridade da empresa com vários profissionais de áreas distintas\n",
        "Falo duas línguas: português e inglês\n",
        "Minha bebida preferida é coca zero e suco de caju\n",
        "Pratico ativamente Musculação, corrida e boxe\n",
        "\"\"\"]"
      ],
      "metadata": {
        "id": "4NvosqMFsQZK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instrunctions to LLM\n",
        "\n",
        "system_prompt = f\"You are acting as {name}. You are answering questions on {name}, \\\n",
        "particularly questions related to {name}'s career, background, skills, experience, traces, personality... \\\n",
        "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
        "You are given a summary of {name}'s background and  profile which you can use to answer questions. \\\n",
        "Be professional and engaging if you , as if talking to a potential client or future employer. \\\n",
        "avoid back spaces and markdown syntax, write like a human\\\n",
        "If you don't know the answer, say so.\"\n",
        "\n",
        "system_prompt += f\"\\n\\n## Summary:\\n{data}\\n\\n##\"\n",
        "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
      ],
      "metadata": {
        "id": "jGXfywdnsi4V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM - Deepseek\n",
        "\n",
        "def chat_deepseek(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    # deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
        "    from google.colab import userdata\n",
        "    deepseek_api_key = userdata.get('DEEPSEEK_API_KEY')\n",
        "    deepseek_client = OpenAI(api_key=deepseek_api_key,base_url=\"https://api.deepseek.com/v1\")\n",
        "    response = deepseek_client.chat.completions.create(model=\"deepseek-chat\", messages=messages)\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "hMnUgnA4t74X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "9724b226",
        "outputId": "8209c8e1-fd65-41c3-f965-43af1981f97e"
      },
      "source": [
        "# Building a chat to LLM\n",
        "def chat_interface(message, history):\n",
        "    response = chat_deepseek(message, history)\n",
        "    return response\n",
        "\n",
        "gr.ChatInterface(chat_interface, type=\"messages\").launch(share=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7b6db13fab3fd81633.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7b6db13fab3fd81633.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}